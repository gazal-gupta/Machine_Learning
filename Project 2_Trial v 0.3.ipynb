{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import missingno as mso\n",
    "import datetime as datetime\n",
    "import calendar\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from sklearn.model_selection import KFold , RandomizedSearchCV,train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score , precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"/Users/1535/OneDrive - Xceedance Consulting India Private Ltd/Gazal Xceedance/EDV/Python/Python Projects/Project 2/carvan_train.csv\"\n",
    "carvan_train=pd.read_csv(file1)\n",
    "\n",
    "file2 = \"/Users/1535/OneDrive - Xceedance Consulting India Private Ltd/Gazal Xceedance/EDV/Python/Python Projects/Project 2/carvan_test.csv\"\n",
    "carvan_test=pd.read_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data size before dropping Id feature is : (5822, 86) \n",
      "The test data size before dropping Id feature is : (4000, 85) \n"
     ]
    }
   ],
   "source": [
    "#check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(carvan_train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(carvan_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 5474\n",
      "Class 1: 348\n",
      "Proportion: 15.73 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_count = carvan_train['V86'].value_counts()\n",
    "\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "carvan_train['data'] = 'Train'\n",
    "carvan_test['data'] = 'Test'\n",
    "carvan_test['V86'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "carvan_test=carvan_test[carvan_train.columns] # the columns in the two data frames should be in the same order to enable concatenation\n",
    "#validation_set=validation_set[carvan_train_over.columns]\n",
    "carvan=pd.concat([carvan_train,carvan_test],axis=0)\n",
    "carvan = carvan.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del carvan['index']\n",
    "carvan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V78  V79  V80  V81  V82  V83  \\\n",
       "0  33   1   3   2   8   0   5   1   3    7  ...    0    0    1    0    0    0   \n",
       "1  37   1   2   2   8   1   4   1   4    6  ...    0    0    1    0    0    0   \n",
       "2  37   1   2   2   8   0   4   2   4    3  ...    0    0    1    0    0    0   \n",
       "3   9   1   3   3   3   2   3   2   4    5  ...    0    0    1    0    0    0   \n",
       "4  40   1   4   2  10   1   4   1   4    7  ...    0    0    1    0    0    0   \n",
       "\n",
       "   V84  V85  V86   data  \n",
       "0    0    0  0.0  Train  \n",
       "1    0    0  0.0  Train  \n",
       "2    0    0  0.0  Train  \n",
       "3    0    0  0.0  Train  \n",
       "4    0    0  0.0  Train  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carvan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train    5822\n",
       "Test     4000\n",
       "Name: data, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carvan.data.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought the data looks numeric but the features are categorical in nature. As per the data disctionary this has been interpreted. Now coverting into Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1 can be dropped , V4num, V5 need to be dropped, V6num\n",
    "\n",
    "New to create - V1\tV5\tV6\tV7\tV8\tV9\tV10\tV11\tV12\tV13\tV14\tV15\tV16\tV17\tV18\tV19\tV20\tV21\tV22\tV23\tV24\tV25\tV26\tV27\tV28\tV29\tV30\tV31\tV32\tV33\tV34\tV35\tV36\t\n",
    "V37\tV38\tV39\tV40\tV41\tV42\tV43 - almost 0 impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"V1\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\n",
    "            \"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"V29\",\"V30\",\"V31\",\"V32\",\"V33\",\"V34\",\"V35\",\n",
    "            \"V36\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    carvan[c]=carvan[c].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not in use\n",
    "#carvan[\"V1\"] = carvan[\"V1\"].astype(str)\n",
    "\n",
    "#carvan[\"V5\"] = carvan[\"V5\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "for c in cat_cols:\n",
    "    print(carvan[c].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "V5\n",
      "V6\n",
      "V7\n",
      "V8\n",
      "V9\n",
      "V10\n",
      "V11\n",
      "V12\n",
      "V13\n",
      "V14\n",
      "V15\n",
      "V16\n",
      "V17\n",
      "V18\n",
      "V19\n",
      "V20\n",
      "V21\n",
      "V22\n",
      "V23\n",
      "V24\n",
      "V25\n",
      "V26\n",
      "V27\n",
      "V28\n",
      "V29\n",
      "V30\n",
      "V31\n",
      "V32\n",
      "V33\n",
      "V34\n",
      "V35\n",
      "V36\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    freqs=carvan[col].value_counts()\n",
    "    selected_cats=freqs.index[freqs>100][:-1]\n",
    "    \n",
    "    print(col)\n",
    "    for cat in selected_cats:\n",
    "        name=col+'_'+cat\n",
    "        \n",
    "        carvan[name]=(carvan[col]==cat).astype(int)\n",
    "    del carvan[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : 2\n"
     ]
    }
   ],
   "source": [
    "for col in carvan.select_dtypes(['object']).columns:\n",
    "    print(col,':',carvan[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 297)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carvan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "carvan_train = carvan[carvan['data'] == 'Train']\n",
    "carvan_test = carvan[carvan['data']=='Test']\n",
    "del carvan_train['data']\n",
    "del carvan_test['data']\n",
    "del carvan_test['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = carvan_train.drop(['V86'],1)\n",
    "Y = carvan_train['V86']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.20,random_state = 42,stratify= Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with Random Forest to check the inital feasibilyt and Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : 0.9296137339055794\n",
      "Recall Score is : 0.05714285714285714\n",
      "Precision Score is : 0.2\n",
      "Auc Score is :  0.5212654924983692\n",
      "Fbeta 2 Score is : 0.5419970631424376\n",
      "[[1079   16]\n",
      " [  66    4]]\n"
     ]
    }
   ],
   "source": [
    "rf_model  = RandomForestClassifier()\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "predicted = rf_model.predict(x_test)\n",
    "\n",
    "print('Accuracy Score is :' , accuracy_score(y_test,predicted))\n",
    "print('Recall Score is :',recall_score(y_test,predicted))\n",
    "print('Precision Score is :',precision_score(y_test,predicted))\n",
    "print('Auc Score is : ', roc_auc_score(y_test,predicted))\n",
    "print('Fbeta 2 Score is :', fbeta_score(predicted,y_test, average='macro', beta=2))\n",
    "print(confusion_matrix(y_test, predicted, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature V2 (0.054775)\n",
      "2. feature V3 (0.048951)\n",
      "3. feature V4 (0.044541)\n",
      "4. feature V44 (0.028800)\n",
      "5. feature V45 (0.027271)\n",
      "6. feature V46 (0.021898)\n",
      "7. feature V47 (0.012791)\n",
      "8. feature V48 (0.012277)\n",
      "9. feature V49 (0.011056)\n",
      "10. feature V50 (0.010816)\n",
      "11. feature V51 (0.010159)\n",
      "12. feature V52 (0.007732)\n",
      "13. feature V53 (0.007272)\n",
      "14. feature V54 (0.006884)\n",
      "15. feature V55 (0.006651)\n",
      "16. feature V56 (0.006248)\n",
      "17. feature V57 (0.005883)\n",
      "18. feature V58 (0.005874)\n",
      "19. feature V59 (0.005838)\n",
      "20. feature V60 (0.005750)\n",
      "21. feature V61 (0.005704)\n",
      "22. feature V62 (0.005405)\n",
      "23. feature V63 (0.005387)\n",
      "24. feature V64 (0.005203)\n",
      "25. feature V65 (0.005168)\n",
      "26. feature V66 (0.005146)\n",
      "27. feature V67 (0.005047)\n",
      "28. feature V68 (0.005012)\n",
      "29. feature V69 (0.004931)\n",
      "30. feature V70 (0.004842)\n",
      "31. feature V71 (0.004823)\n",
      "32. feature V72 (0.004758)\n",
      "33. feature V73 (0.004753)\n",
      "34. feature V74 (0.004732)\n",
      "35. feature V75 (0.004719)\n",
      "36. feature V76 (0.004669)\n",
      "37. feature V77 (0.004521)\n",
      "38. feature V78 (0.004508)\n",
      "39. feature V79 (0.004495)\n",
      "40. feature V80 (0.004468)\n",
      "41. feature V81 (0.004447)\n",
      "42. feature V82 (0.004429)\n",
      "43. feature V83 (0.004372)\n",
      "44. feature V84 (0.004368)\n",
      "45. feature V85 (0.004329)\n",
      "46. feature V1_33 (0.004309)\n",
      "47. feature V1_38 (0.004250)\n",
      "48. feature V1_8 (0.004247)\n",
      "49. feature V1_39 (0.004209)\n",
      "50. feature V1_9 (0.004207)\n",
      "51. feature V1_3 (0.004178)\n",
      "52. feature V1_23 (0.004147)\n",
      "53. feature V1_36 (0.004140)\n",
      "54. feature V1_35 (0.004139)\n",
      "55. feature V1_41 (0.004138)\n",
      "56. feature V1_34 (0.004075)\n",
      "57. feature V1_24 (0.004006)\n",
      "58. feature V1_31 (0.004004)\n",
      "59. feature V1_13 (0.003998)\n",
      "60. feature V1_11 (0.003987)\n",
      "61. feature V1_10 (0.003983)\n",
      "62. feature V1_32 (0.003958)\n",
      "63. feature V1_37 (0.003929)\n",
      "64. feature V1_1 (0.003923)\n",
      "65. feature V1_6 (0.003874)\n",
      "66. feature V1_12 (0.003864)\n",
      "67. feature V1_30 (0.003858)\n",
      "68. feature V1_22 (0.003841)\n",
      "69. feature V1_2 (0.003747)\n",
      "70. feature V1_29 (0.003747)\n",
      "71. feature V1_40 (0.003722)\n",
      "72. feature V5_8 (0.003721)\n",
      "73. feature V5_3 (0.003685)\n",
      "74. feature V5_9 (0.003676)\n",
      "75. feature V5_1 (0.003602)\n",
      "76. feature V5_5 (0.003597)\n",
      "77. feature V5_7 (0.003562)\n",
      "78. feature V5_2 (0.003552)\n",
      "79. feature V5_10 (0.003547)\n",
      "80. feature V6_0 (0.003526)\n",
      "81. feature V6_1 (0.003482)\n",
      "82. feature V6_2 (0.003447)\n",
      "83. feature V6_3 (0.003447)\n",
      "84. feature V7_4 (0.003398)\n",
      "85. feature V7_5 (0.003394)\n",
      "86. feature V7_6 (0.003383)\n",
      "87. feature V7_3 (0.003370)\n",
      "88. feature V7_7 (0.003361)\n",
      "89. feature V7_2 (0.003357)\n",
      "90. feature V7_9 (0.003356)\n",
      "91. feature V7_1 (0.003322)\n",
      "92. feature V7_0 (0.003316)\n",
      "93. feature V8_0 (0.003294)\n",
      "94. feature V8_1 (0.003277)\n",
      "95. feature V8_2 (0.003273)\n",
      "96. feature V8_3 (0.003271)\n",
      "97. feature V9_3 (0.003230)\n",
      "98. feature V9_4 (0.003223)\n",
      "99. feature V9_2 (0.003222)\n",
      "100. feature V9_5 (0.003179)\n",
      "101. feature V9_0 (0.003105)\n",
      "102. feature V9_6 (0.003054)\n",
      "103. feature V9_1 (0.003025)\n",
      "104. feature V10_7 (0.003000)\n",
      "105. feature V10_6 (0.002978)\n",
      "106. feature V10_5 (0.002974)\n",
      "107. feature V10_9 (0.002857)\n",
      "108. feature V10_8 (0.002855)\n",
      "109. feature V10_4 (0.002812)\n",
      "110. feature V10_3 (0.002812)\n",
      "111. feature V10_2 (0.002811)\n",
      "112. feature V10_1 (0.002807)\n",
      "113. feature V11_0 (0.002805)\n",
      "114. feature V11_1 (0.002728)\n",
      "115. feature V11_2 (0.002707)\n",
      "116. feature V11_3 (0.002668)\n",
      "117. feature V12_2 (0.002655)\n",
      "118. feature V12_0 (0.002649)\n",
      "119. feature V12_3 (0.002643)\n",
      "120. feature V12_4 (0.002640)\n",
      "121. feature V12_1 (0.002628)\n",
      "122. feature V12_5 (0.002589)\n",
      "123. feature V13_0 (0.002568)\n",
      "124. feature V13_2 (0.002544)\n",
      "125. feature V13_1 (0.002521)\n",
      "126. feature V13_3 (0.002491)\n",
      "127. feature V13_4 (0.002459)\n",
      "128. feature V13_5 (0.002443)\n",
      "129. feature V13_6 (0.002442)\n",
      "130. feature V14_3 (0.002430)\n",
      "131. feature V14_4 (0.002390)\n",
      "132. feature V14_2 (0.002372)\n",
      "133. feature V14_5 (0.002369)\n",
      "134. feature V14_0 (0.002366)\n",
      "135. feature V14_1 (0.002357)\n",
      "136. feature V14_6 (0.002349)\n",
      "137. feature V15_4 (0.002347)\n",
      "138. feature V15_5 (0.002341)\n",
      "139. feature V15_3 (0.002323)\n",
      "140. feature V15_6 (0.002319)\n",
      "141. feature V15_2 (0.002313)\n",
      "142. feature V15_7 (0.002312)\n",
      "143. feature V15_1 (0.002308)\n",
      "144. feature V15_8 (0.002288)\n",
      "145. feature V15_9 (0.002278)\n",
      "146. feature V16_0 (0.002268)\n",
      "147. feature V16_1 (0.002263)\n",
      "148. feature V16_2 (0.002252)\n",
      "149. feature V16_3 (0.002223)\n",
      "150. feature V16_4 (0.002212)\n",
      "151. feature V16_5 (0.002211)\n",
      "152. feature V17_4 (0.002210)\n",
      "153. feature V17_3 (0.002203)\n",
      "154. feature V17_2 (0.002178)\n",
      "155. feature V17_5 (0.002153)\n",
      "156. feature V17_0 (0.002124)\n",
      "157. feature V17_1 (0.002111)\n",
      "158. feature V17_6 (0.002109)\n",
      "159. feature V18_5 (0.002103)\n",
      "160. feature V18_6 (0.002088)\n",
      "161. feature V18_4 (0.002081)\n",
      "162. feature V18_3 (0.002068)\n",
      "163. feature V18_2 (0.002064)\n",
      "164. feature V18_7 (0.002032)\n",
      "165. feature V18_9 (0.002030)\n",
      "166. feature V18_0 (0.002010)\n",
      "167. feature V18_8 (0.001994)\n",
      "168. feature V19_0 (0.001993)\n",
      "169. feature V19_2 (0.001991)\n",
      "170. feature V19_1 (0.001982)\n",
      "171. feature V19_3 (0.001952)\n",
      "172. feature V19_4 (0.001943)\n",
      "173. feature V19_5 (0.001926)\n",
      "174. feature V19_6 (0.001923)\n",
      "175. feature V20_0 (0.001915)\n",
      "176. feature V20_1 (0.001911)\n",
      "177. feature V21_0 (0.001910)\n",
      "178. feature V21_1 (0.001900)\n",
      "179. feature V21_2 (0.001895)\n",
      "180. feature V21_3 (0.001894)\n",
      "181. feature V21_4 (0.001862)\n",
      "182. feature V22_2 (0.001858)\n",
      "183. feature V22_3 (0.001854)\n",
      "184. feature V22_4 (0.001840)\n",
      "185. feature V22_0 (0.001831)\n",
      "186. feature V22_5 (0.001814)\n",
      "187. feature V22_1 (0.001814)\n",
      "188. feature V22_6 (0.001751)\n",
      "189. feature V22_7 (0.001742)\n",
      "190. feature V23_2 (0.001718)\n",
      "191. feature V23_0 (0.001718)\n",
      "192. feature V23_3 (0.001703)\n",
      "193. feature V23_1 (0.001675)\n",
      "194. feature V23_4 (0.001673)\n",
      "195. feature V23_5 (0.001667)\n",
      "196. feature V23_6 (0.001649)\n",
      "197. feature V24_2 (0.001642)\n",
      "198. feature V24_3 (0.001616)\n",
      "199. feature V24_1 (0.001603)\n",
      "200. feature V24_0 (0.001602)\n",
      "201. feature V24_4 (0.001596)\n",
      "202. feature V24_5 (0.001572)\n",
      "203. feature V24_6 (0.001548)\n",
      "204. feature V25_0 (0.001537)\n",
      "205. feature V25_1 (0.001522)\n",
      "206. feature V25_2 (0.001522)\n",
      "207. feature V25_3 (0.001518)\n",
      "208. feature V25_4 (0.001467)\n",
      "209. feature V25_5 (0.001453)\n",
      "210. feature V25_6 (0.001444)\n",
      "211. feature V25_7 (0.001442)\n",
      "212. feature V26_2 (0.001441)\n",
      "213. feature V26_1 (0.001439)\n",
      "214. feature V26_0 (0.001429)\n",
      "215. feature V26_3 (0.001410)\n",
      "216. feature V26_4 (0.001398)\n",
      "217. feature V27_2 (0.001395)\n",
      "218. feature V27_3 (0.001391)\n",
      "219. feature V27_0 (0.001390)\n",
      "220. feature V27_1 (0.001387)\n",
      "221. feature V27_4 (0.001381)\n",
      "222. feature V27_5 (0.001380)\n",
      "223. feature V28_5 (0.001378)\n",
      "224. feature V28_4 (0.001337)\n",
      "225. feature V28_3 (0.001331)\n",
      "226. feature V28_2 (0.001317)\n",
      "227. feature V28_6 (0.001305)\n",
      "228. feature V28_0 (0.001304)\n",
      "229. feature V28_1 (0.001288)\n",
      "230. feature V28_7 (0.001287)\n",
      "231. feature V28_9 (0.001283)\n",
      "232. feature V29_0 (0.001262)\n",
      "233. feature V29_1 (0.001257)\n",
      "234. feature V29_2 (0.001212)\n",
      "235. feature V29_3 (0.001192)\n",
      "236. feature V29_4 (0.001191)\n",
      "237. feature V30_0 (0.001164)\n",
      "238. feature V30_9 (0.001150)\n",
      "239. feature V30_2 (0.001143)\n",
      "240. feature V30_3 (0.001141)\n",
      "241. feature V30_4 (0.001118)\n",
      "242. feature V30_8 (0.001115)\n",
      "243. feature V30_5 (0.001114)\n",
      "244. feature V30_1 (0.001112)\n",
      "245. feature V30_7 (0.001112)\n",
      "246. feature V31_9 (0.001105)\n",
      "247. feature V31_0 (0.001089)\n",
      "248. feature V31_7 (0.001075)\n",
      "249. feature V31_6 (0.001069)\n",
      "250. feature V31_5 (0.001067)\n",
      "251. feature V31_1 (0.001059)\n",
      "252. feature V31_4 (0.001054)\n",
      "253. feature V31_8 (0.001041)\n",
      "254. feature V31_2 (0.001037)\n",
      "255. feature V32_6 (0.001034)\n",
      "256. feature V32_7 (0.001024)\n",
      "257. feature V32_5 (0.001021)\n",
      "258. feature V32_9 (0.001006)\n",
      "259. feature V32_4 (0.001004)\n",
      "260. feature V32_8 (0.000979)\n",
      "261. feature V32_3 (0.000974)\n",
      "262. feature V33_0 (0.000972)\n",
      "263. feature V33_2 (0.000971)\n",
      "264. feature V33_1 (0.000943)\n",
      "265. feature V33_3 (0.000936)\n",
      "266. feature V33_4 (0.000932)\n",
      "267. feature V34_2 (0.000926)\n",
      "268. feature V34_0 (0.000906)\n",
      "269. feature V34_3 (0.000897)\n",
      "270. feature V34_1 (0.000864)\n",
      "271. feature V34_4 (0.000856)\n",
      "272. feature V34_5 (0.000854)\n",
      "273. feature V35_7 (0.000853)\n",
      "274. feature V35_5 (0.000853)\n",
      "275. feature V35_6 (0.000850)\n",
      "276. feature V35_9 (0.000828)\n",
      "277. feature V35_8 (0.000784)\n",
      "278. feature V35_4 (0.000773)\n",
      "279. feature V35_2 (0.000771)\n",
      "280. feature V35_3 (0.000748)\n",
      "281. feature V36_2 (0.000724)\n",
      "282. feature V36_4 (0.000721)\n",
      "283. feature V36_0 (0.000705)\n",
      "284. feature V36_3 (0.000679)\n",
      "285. feature V36_1 (0.000677)\n",
      "286. feature V36_5 (0.000668)\n",
      "287. feature V36_7 (0.000659)\n",
      "288. feature V36_6 (0.000639)\n",
      "289. feature V37_0 (0.000612)\n",
      "290. feature V37_2 (0.000603)\n",
      "291. feature V37_3 (0.000578)\n",
      "292. feature V37_1 (0.000571)\n",
      "293. feature V37_4 (0.000558)\n",
      "294. feature V37_5 (0.000527)\n",
      "295. feature V37_6 (0.000520)\n",
      "296. feature V38_4 (0.000502)\n",
      "297. feature V38_3 (0.000495)\n",
      "298. feature V38_5 (0.000481)\n",
      "299. feature V38_2 (0.000468)\n",
      "300. feature V38_0 (0.000433)\n",
      "301. feature V38_6 (0.000416)\n",
      "302. feature V38_1 (0.000400)\n",
      "303. feature V38_7 (0.000399)\n",
      "304. feature V39_3 (0.000387)\n",
      "305. feature V39_2 (0.000379)\n",
      "306. feature V39_4 (0.000379)\n",
      "307. feature V39_0 (0.000377)\n",
      "308. feature V39_1 (0.000357)\n",
      "309. feature V39_5 (0.000341)\n",
      "310. feature V39_6 (0.000337)\n",
      "311. feature V39_7 (0.000313)\n",
      "312. feature V40_0 (0.000302)\n",
      "313. feature V40_1 (0.000236)\n",
      "314. feature V40_2 (0.000214)\n",
      "315. feature V40_3 (0.000213)\n",
      "316. feature V40_4 (0.000205)\n",
      "317. feature V41_0 (0.000191)\n",
      "318. feature V41_1 (0.000162)\n",
      "319. feature V42_3 (0.000148)\n",
      "320. feature V42_4 (0.000113)\n",
      "321. feature V42_5 (0.000112)\n",
      "322. feature V42_2 (0.000070)\n",
      "323. feature V42_6 (0.000059)\n",
      "324. feature V42_7 (0.000000)\n",
      "325. feature V43_3 (0.000000)\n",
      "326. feature V43_6 (0.000000)\n",
      "327. feature V43_4 (0.000000)\n",
      "328. feature V43_5 (0.000000)\n",
      "329. feature V43_1 (0.000000)\n",
      "330. feature V43_7 (0.000000)\n",
      "331. feature V43_2 (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, list(x_train.columns)[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_train.shape[1]), list(x_train.columns))\n",
    "plt.xlim([-1, x_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with XG Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : 0.9399141630901288\n",
      "Recall Score is : 0.0\n",
      "Precision Score is : 0.0\n",
      "Auc Score is :  0.5\n",
      "Fbeta 2 Score is : 0.4756733275412684\n",
      "Fbeta 2 Score is : [[1095    0]\n",
      " [  70    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "XG_clf=XGBClassifier(objective='binary:logistic')\n",
    "XG_clf.fit(x_train,y_train)\n",
    "predicted = XG_clf.predict(x_test)\n",
    "\n",
    "print('Accuracy Score is :' , accuracy_score(y_test,predicted))\n",
    "print('Recall Score is :',recall_score(y_test,predicted))\n",
    "print('Precision Score is :',precision_score(y_test,predicted))\n",
    "print('Auc Score is : ', roc_auc_score(y_test,predicted))\n",
    "print('Fbeta 2 Score is :', fbeta_score(predicted,y_test, average='macro', beta=2))\n",
    "print('Fbeta 2 Score is :', confusion_matrix(y_test, predicted, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost with Parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_clf1=XGBClassifier(objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {  \n",
    "                \"learning_rate\":[0.01,0.05,0.1,0.3,0.5],\n",
    "                \"gamma\":[i/10.0 for i in range(0,5)],\n",
    "                \"max_depth\": [2,3,4,5,6,7,8],\n",
    "                \"min_child_weight\":[1,2,5,10],\n",
    "                \"max_delta_step\":[0,1,2,5,10],\n",
    "                \"subsample\":[i/10.0 for i in range(5,10)],\n",
    "                \"colsample_bytree\":[i/10.0 for i in range(5,10)],\n",
    "                \"colsample_bylevel\":[i/10.0 for i in range(5,10)],\n",
    "                \"reg_lambda\":[1e-5, 1e-2, 0.1, 1, 100], \n",
    "                \"reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                \"scale_pos_weight\":[1,2,3,4,5],\n",
    "                \"n_estimators\":[100,500,700,1000]\n",
    "             }\n",
    "\n",
    "n_iter=10\n",
    "\n",
    "random_search=RandomizedSearchCV(XG_clf1,n_jobs=-1,verbose=3,cv=5,n_iter=n_iter,scoring='roc_auc',\n",
    "                                 param_distributions=xgb_params)\n",
    "\n",
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after best parameter is learnt\n",
    "xgb_best=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
    "       colsample_bynode=1, colsample_bytree=0.7, gamma=0.1,\n",
    "       learning_rate=0.01, max_delta_step=1, max_depth=5,\n",
    "       min_child_weight=2, missing=None, n_estimators=1000, n_jobs=1,\n",
    "       nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0.1, reg_lambda=100, scale_pos_weight=5, seed=None,\n",
    "       silent=None, subsample=0.5, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bynode=1, colsample_bytree=0.7, gamma=0.1,\n",
       "       learning_rate=0.01, max_delta_step=1, max_depth=5,\n",
       "       min_child_weight=2, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0.1, reg_lambda=100, scale_pos_weight=5, seed=None,\n",
       "       silent=None, subsample=0.5, verbosity=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : 0.9175965665236051\n",
      "Recall Score is : 0.2\n",
      "Precision Score is : 0.25925925925925924\n",
      "Auc Score is :  0.5817351598173516\n",
      "Fbeta 2 Score is : 0.5985466059486642\n",
      "Confusion Matrix : [[1055   40]\n",
      " [  56   14]]\n"
     ]
    }
   ],
   "source": [
    "predicted = xgb_best.predict(x_test)\n",
    "\n",
    "print('Accuracy Score is :' , accuracy_score(y_test,predicted))\n",
    "print('Recall Score is :',recall_score(y_test,predicted))\n",
    "print('Precision Score is :',precision_score(y_test,predicted))\n",
    "print('Auc Score is : ', roc_auc_score(y_test,predicted))\n",
    "print('Fbeta 2 Score is :', fbeta_score(predicted,y_test, average='macro', beta=2))\n",
    "print('Confusion Matrix :', confusion_matrix(y_test, predicted, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out the correct probabilty cutoff to predict hard classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "       0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77,\n",
       "       0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88,\n",
       "       0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs=np.linspace(0.01,0.99,99)\n",
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_score=xgb_best.predict_proba(x_train)[:,1] # the predicted response variable values\n",
    "real=y_train # the actual response variable values\n",
    "print(xgb_best.classes_) # In order to find the probability of which column is for outcome 1 and which for outcome 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_all=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted=(train_score>cutoff).astype(int)\n",
    "    \n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "    \n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_all.append(KS)\n",
    "    \n",
    "# try out what cutoffs you get when you use F_beta scores with different values of betas [0.5 , 5]\n",
    "# beta < 1 : you will get cutoff , which is high ( favours precision)\n",
    "# beta > 1 : you will get cutoff , which is low (favours precision )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.0),\n",
       " (0.02, 0.0),\n",
       " (0.03, 0.0013701758392327124),\n",
       " (0.04, 0.019410824389129888),\n",
       " (0.05, 0.06828042932176293),\n",
       " (0.060000000000000005, 0.1356474080840374),\n",
       " (0.06999999999999999, 0.2068965517241379),\n",
       " (0.08, 0.27083809088833066),\n",
       " (0.09, 0.3274720255766157),\n",
       " (0.09999999999999999, 0.3709742870239091),\n",
       " (0.11, 0.4116795168569415),\n",
       " (0.12, 0.44918766973176427),\n",
       " (0.13, 0.4832703830085053),\n",
       " (0.14, 0.5142126992628323),\n",
       " (0.15000000000000002, 0.53876086160074),\n",
       " (0.16, 0.5614254428838752),\n",
       " (0.17, 0.5816913950000082),\n",
       " (0.18000000000000002, 0.6065829227460688),\n",
       " (0.19, 0.6222816220647598),\n",
       " (0.2, 0.6298159462838498),\n",
       " (0.21000000000000002, 0.6490550879689032),\n",
       " (0.22, 0.6596731292746119),\n",
       " (0.23, 0.6597281663137177),\n",
       " (0.24000000000000002, 0.6577279395939745),\n",
       " (0.25, 0.6557277128742313),\n",
       " (0.26, 0.6600082801993162),\n",
       " (0.27, 0.6397373993931139),\n",
       " (0.28, 0.638537263361268),\n",
       " (0.29000000000000004, 0.6351101808664966),\n",
       " (0.3, 0.6386489803361695),\n",
       " (0.31, 0.6331666340825489),\n",
       " (0.32, 0.6166645582825815),\n",
       " (0.33, 0.6120956625884495),\n",
       " (0.34, 0.6050147778557241),\n",
       " (0.35000000000000003, 0.5973054851391779),\n",
       " (0.36000000000000004, 0.5877126113678593),\n",
       " (0.37, 0.5624177524844706),\n",
       " (0.38, 0.5544234171922567),\n",
       " (0.39, 0.5441454555013217),\n",
       " (0.4, 0.5300420088683563),\n",
       " (0.41000000000000003, 0.506974096447893),\n",
       " (0.42000000000000004, 0.49401246301428825),\n",
       " (0.43, 0.4763118940791646),\n",
       " (0.44, 0.45278725637895717),\n",
       " (0.45, 0.43891217238586383),\n",
       " (0.46, 0.41401735884642366),\n",
       " (0.47000000000000003, 0.3990004616539698),\n",
       " (0.48000000000000004, 0.38512537766087657),\n",
       " (0.49, 0.37484741596994153),\n",
       " (0.5, 0.35646175911520156),\n",
       " (0.51, 0.3378477396205894),\n",
       " (0.52, 0.33071017495206845),\n",
       " (0.53, 0.30667213203632115),\n",
       " (0.54, 0.2905134216445067),\n",
       " (0.55, 0.27167103951002247),\n",
       " (0.56, 0.25528396647833596),\n",
       " (0.5700000000000001, 0.23621322170397963),\n",
       " (0.5800000000000001, 0.21982614867229303),\n",
       " (0.59, 0.21582898102618614),\n",
       " (0.6, 0.19675823625182978),\n",
       " (0.61, 0.18733704518458766),\n",
       " (0.62, 0.16780957513048705),\n",
       " (0.63, 0.1550196244009588),\n",
       " (0.64, 0.14154458575181417),\n",
       " (0.65, 0.13526379170698608),\n",
       " (0.66, 0.10425986682679432),\n",
       " (0.67, 0.08673098059574719),\n",
       " (0.68, 0.07999346127117489),\n",
       " (0.6900000000000001, 0.06246457504012775),\n",
       " (0.7000000000000001, 0.048076085831494655),\n",
       " (0.7100000000000001, 0.04516405144895273),\n",
       " (0.72, 0.024266405555619444),\n",
       " (0.73, 0.020897645893333292),\n",
       " (0.74, 0.017300523591175017),\n",
       " (0.75, 0.017528886231047133),\n",
       " (0.76, 0.010334641626730586),\n",
       " (0.77, 0.0067375193245723134),\n",
       " (0.78, 0.0067375193245723134),\n",
       " (0.79, 0.0067375193245723134),\n",
       " (0.8, 0.00696588196444443),\n",
       " (0.81, 0.0),\n",
       " (0.8200000000000001, 0.0),\n",
       " (0.8300000000000001, 0.0),\n",
       " (0.8400000000000001, 0.0),\n",
       " (0.85, 0.0),\n",
       " (0.86, 0.0),\n",
       " (0.87, 0.0),\n",
       " (0.88, 0.0),\n",
       " (0.89, 0.0),\n",
       " (0.9, 0.0),\n",
       " (0.91, 0.0),\n",
       " (0.92, 0.0),\n",
       " (0.93, 0.0),\n",
       " (0.9400000000000001, 0.0),\n",
       " (0.9500000000000001, 0.0),\n",
       " (0.9600000000000001, 0.0),\n",
       " (0.97, 0.0),\n",
       " (0.98, 0.0),\n",
       " (0.99, 0.0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cutoffs,KS_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycutoff=cutoffs[KS_all==max(KS_all)][0]\n",
    "mycutoff # gives the cutoff value where KS is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09644467, 0.6104807 , 0.3723423 , ..., 0.32952014, 0.3532237 ,\n",
       "       0.20372385], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score=xgb_best.predict_proba(carvan_test)[:,1]\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "test_classes=(test_score>mycutoff).astype(int)\n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_classes).to_csv(\"Project2_Part2_0.2.csv\",index=False)\n",
    "# Please give the file a proper name before submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
