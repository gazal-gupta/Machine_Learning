What is Web Scraping?
Web scraping, also known as web data extraction, is formally known as the process of obtaining and structuring data from the web using intelligent
automation. It can be used to potentially retrieve hundreds, millions, or even billions of data points from the internet’s seemingly endless frontier

Beautiful Soup

Beautiful Soup is a Python library for extracting data from an HTML document It achieves that by analyzing the HTML with a
parser. The most useful methods of the package are:

•.find(“p”, class=“footer text”) extracts the first paragraph tag with class = “footer text”
• find_all (“a”) extracts all links from the page
• tag.attrs returns a dictionary of all attributes of this tag
• tag.text returns all the text in this tag
• tag.contents returns a list of all children elements of this tag

Common roadblocks when scraping
1. Identification: Some websites may require us to identify ourselves – the solution is to set the “User-Agent” request header to one
of the common browsers.
2. Cookies: Other websites may require us to set cookies – solution: use the session class of the request's library.
3. Login: Occasionally, the data we want to scrape may be locked behind a login. In that case, we need to simulate a login
attempt by inspecting the POST request that is sent and its parameters.
4. Excessive requests: Another roadblock may occur when we send too much requests in a short amount of time to a server. Therefore,
we may get blocked. Out of ethical standpoint as well, it is a good idea to limit our rate of requests. We can
simply do that with the sleep function of the time package -> time.sleep(2).
